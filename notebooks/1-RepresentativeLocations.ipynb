{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c75a7b-f11f-4d9b-a432-2c2399f7d9d6",
   "metadata": {},
   "source": [
    "# 1. Representative Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6b31d-113c-4ada-b610-dd7c1c3dfd04",
   "metadata": {},
   "source": [
    "xxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e25c496-e902-4888-85d3-a2a944283c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd282ba4-4602-48a3-b466-8b796f52a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representative_locations(file_path, output_name):\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate the count of observations for each location\n",
    "    num_obs_per_location = data.groupby('location').size().reset_index(name='num_obs')\n",
    "\n",
    "    # Remove duplicate points\n",
    "    data_no_duplicates = data.drop_duplicates(subset=['lat', 'long'])\n",
    "\n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data_no_duplicates[['lat', 'long']])\n",
    "\n",
    "    # Clustering\n",
    "    num_clusters = min(len(data_no_duplicates), 5)  # Adjusting number of clusters\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "    data_no_duplicates = data_no_duplicates.copy()\n",
    "    data_no_duplicates['cluster'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "    # Select Representative Locations by which ones have the most observations\n",
    "    representative_locations = data_no_duplicates.groupby('cluster').apply(lambda x: x.max())\n",
    "    \n",
    "    representative_locations = representative_locations[['cluster', 'location', 'lat', 'long']]\n",
    "    \n",
    "    # Merge representative locations with the count of observations\n",
    "    representative_locations = pd.merge(representative_locations, num_obs_per_location, on='location', how='left')\n",
    "\n",
    "    # Get bloom data for each location\n",
    "    location_data = [data[data['location'] == row['location']] for _, row in representative_locations.iterrows()]\n",
    "\n",
    "    return data_no_duplicates[['cluster', 'location', 'lat', 'long']], representative_locations, location_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a91841-df83-462c-875b-6a8b7fb51162",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERS_FOLDER = \"../data/interim/representative_locations/clusters/\"\n",
    "LOCATIONS_FOLDER = \"../data/interim/representative_locations/location/\"\n",
    "VALIDATION_FOLDER = \"../data/interim/representative_locations/validation/\"\n",
    "\n",
    "location_dict = {\n",
    "    \"korea\":\"/Users/simonaytes/Documents/GitHub/cherry-blossom/data/raw/south_korea.csv\",\n",
    "    \"japan\":\"/Users/simonaytes/Documents/GitHub/cherry-blossom/data/raw/japan.csv\",\n",
    "    \"switzerland\":\"/Users/simonaytes/Documents/GitHub/cherry-blossom/data/raw/meteoswiss.csv\",\n",
    "    \"usa\":\"/Users/simonaytes/Documents/GitHub/cherry-blossom/data/raw/usa_formatted.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb14500d-aa26-492f-9661-06de3b281f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each file, find its representative locations\n",
    "for location in location_dict:\n",
    "    clusters, rep_locations, loc_data = get_representative_locations(location_dict[location], location)\n",
    "\n",
    "    # Output the cluster data\n",
    "    clusters.to_csv(f\"{CLUSTERS_FOLDER}{location}_clusters.csv\", index=False)\n",
    "\n",
    "    # Output the representative location lists\n",
    "    rep_locations.to_csv(f\"{LOCATIONS_FOLDER}{location}_representative_locations.csv\", index=False)\n",
    "\n",
    "    # Ouput location-specific validation data\n",
    "    for i in range(0, len(loc_data)):\n",
    "        loc_data[i].to_csv(f\"{VALIDATION_FOLDER}{location}_{i+1}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
