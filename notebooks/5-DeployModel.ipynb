{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bf78af-0541-4c63-a661-92105192ea54",
   "metadata": {},
   "source": [
    "# 5. Deploy Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538c37c-3c5d-4cc6-ac2b-8f154f26bab4",
   "metadata": {},
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f113b-1a70-4602-89ee-66ed558a5470",
   "metadata": {},
   "source": [
    "## 5.1 Environment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565dd3e-d5cb-4ee2-a1df-82a417660ed7",
   "metadata": {},
   "source": [
    "### 5.1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e8a7d1-7e56-458c-85bf-80b4e190e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a482c25f-7105-4d6d-ac2c-085bfee80117",
   "metadata": {},
   "source": [
    "### 5.1.2 Define Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29eddfba-8d5f-4275-9a51-b3a0acaf42b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_new_data(new_data, normalization_params):\n",
    "    # Ensure the input data is a numpy array\n",
    "    if isinstance(new_data, np.ndarray):\n",
    "        # Normalize each feature using the stored mean and standard deviation\n",
    "        normalized_data = (new_data - normalization_params['mean']) / normalization_params['std']\n",
    "        return normalized_data\n",
    "    elif isinstance(new_data, pd.DataFrame):\n",
    "        # Normalize each column (feature) using the stored mean and standard deviation\n",
    "        normalized_data = (new_data - normalization_params['mean']) / normalization_params['std']\n",
    "        return normalized_data\n",
    "    else:\n",
    "        raise ValueError(\"Input data must be a numpy array or pandas DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35da7954-4005-43f4-b88e-8863ea8f9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_interval(x, model, alpha=0.05):\n",
    "    # Get the mean prediction\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # Calculate the standard deviation of predictions\n",
    "    std_dev = np.std(y_pred)\n",
    "    \n",
    "    # Calculate the z-score for the given significance level\n",
    "    z_score = np.abs(norm.ppf(alpha / 2))\n",
    "    \n",
    "    # Calculate margin of error\n",
    "    margin_of_error = z_score * std_dev\n",
    "    \n",
    "    # Calculate prediction interval\n",
    "    lower_bound = y_pred - margin_of_error\n",
    "    upper_bound = y_pred + margin_of_error\n",
    "\n",
    "    # Convert predictions to integers\n",
    "    lower_bound = np.round(lower_bound).astype(int)\n",
    "    upper_bound = np.round(upper_bound).astype(int)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c84e03-98cd-418e-a15a-f0079b90cf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(x, model):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    # Convert predictions to integers\n",
    "    predictions = np.round(y_pred).astype(int)\n",
    "\n",
    "    lower_bound, upper_bound = prediction_interval(x, model, alpha=0.75)\n",
    "\n",
    "    return list(predictions), list(lower_bound), list(upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59910eba-8792-4683-9bf4-547622153239",
   "metadata": {},
   "source": [
    "## 5.2 Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f9778-f73e-4998-8ac9-b5774a780fcd",
   "metadata": {},
   "source": [
    "### 5.2.1 Import Model & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ee8882-dd84-4578-97e5-5f3366b8d833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the model to load\n",
    "model_dir_path = \"../models/GBR-20240218-01/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f1149f-425d-4104-aac4-7e266f2c6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = joblib.load(f'{model_dir_path}model.pkl')\n",
    "\n",
    "# Load the normalization parameters\n",
    "normalization_params = joblib.load(f'{model_dir_path}normalization_params.pkl')\n",
    "\n",
    "# Load the feature names\n",
    "feature_list = joblib.load(f'{model_dir_path}feature_list.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5676a-87c8-4117-8a83-9e55ba71554a",
   "metadata": {},
   "source": [
    "## 5.3 Load New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e50587d0-d813-4bb3-9ae5-5f7b54e09f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Path to CSV File:  /Users/simonaytes/Documents/GitHub/cherry-blossom/data/inputs/competition_input.csv\n"
     ]
    }
   ],
   "source": [
    "# Load new data here\n",
    "file_path = input(\"Path to CSV File: \")\n",
    "\n",
    "input_df = pd.read_csv(file_path)\n",
    "input_df = input_df[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f12b0107-2532-44aa-8896-9b9d49f890c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "input_df = normalize_new_data(input_df, normalization_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2025df6-3462-4800-9d62-dd57dc7c9037",
   "metadata": {},
   "source": [
    "## 5.4 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d094e5d3-17be-4a3e-994c-5fc3e2527df1",
   "metadata": {},
   "source": [
    "### 5.4.1 Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e50486e6-cfc9-4b17-8165-b7d7bc4846cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/base.py:413: UserWarning: X has feature names, but GradientBoostingRegressor was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "predictions, lower_bound, upper_bound = get_predictions(input_df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e206c323-d3d5-48f6-bc5a-41766f0d9486",
   "metadata": {},
   "source": [
    "### 5.4.2 Create Prediction Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758bb796-d570-4bdb-a98f-f5440bb2b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv(file_path)[['location']]\n",
    "predictions_df[\"prediction\"] = predictions\n",
    "predictions_df[\"lower\"] = lower_bound\n",
    "predictions_df[\"upper\"] = upper_bound\n",
    "\n",
    "predictions_df = predictions_df[['location', 'prediction', 'lower', 'upper']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fff272-d0a5-40f9-9558-c7f021c46d65",
   "metadata": {},
   "source": [
    "### 5.4.3 Output Prediction Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3968bd8d-3488-4396-93ac-5198c1741238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output filename using the current timestamp\n",
    "output_file_name = f\"../data/output/{dt.now().strftime('%Y-%m-%d_%H-%M-%S') + '.csv'}\"\n",
    "\n",
    "# Output the dataframe\n",
    "predictions_df.to_csv(output_file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
