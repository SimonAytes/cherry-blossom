{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56739780-7ca8-4694-8bb6-e1ffce832fca",
   "metadata": {},
   "source": [
    "# 3. Combine Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ee24e-0e30-461f-92a3-0934ad3c70af",
   "metadata": {},
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4adc0c48-4824-4e3e-88c8-7daf07e8e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6308de-f83f-46e4-96ba-43a21c8a24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_PATHS = [\"../data/interim/representative_locations/validation/\",\n",
    "                    \"../data/interim/main_locations/validation\"]\n",
    "\n",
    "CLEANED_PATHS = [\"../data/interim/representative_locations/weather/monthly_agg/\",\n",
    "                 \"../data/interim/main_locations/weather/monthly_agg\"]\n",
    "\n",
    "INDIV_OUT_PATH = \"../data/cleaned/individual/\"\n",
    "COMBINED_OUT_PATH = \"../data/cleaned/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f6aefa-752d-43c4-a7bb-7d20e1906622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(v_path, c_path):\n",
    "    # Rearrange the columns in the validation dataset\n",
    "    validation_columns_format = ['location', 'bloom_doy', 'year', 'lat', 'long', 'bloom_date', 'alt']\n",
    "    \n",
    "    # Load in validation df\n",
    "    v_df = pd.read_csv(v_path)\n",
    "    v_df = v_df[validation_columns_format]\n",
    "\n",
    "    # Make extra column to ease merge\n",
    "    v_df['pred_year'] = v_df['year'] - 1\n",
    "\n",
    "    # Drop unused column\n",
    "    v_df = v_df.drop(columns=['year'])\n",
    "\n",
    "    # Load in cleaned df\n",
    "    c_df = pd.read_csv(c_path)\n",
    "\n",
    "    # Drop unused column\n",
    "    c_df = c_df.drop(columns=[\"location\"])\n",
    "    \n",
    "    # Combine them on the 'pred_year'='year'\n",
    "    combined_df = pd.merge(v_df, c_df, left_on='pred_year', right_on='year', how='inner')\n",
    "\n",
    "    # Drop unused columns\n",
    "    combined_df = combined_df.drop(columns=[\"pred_year\", 'year'])\n",
    "\n",
    "    # Cast column to datetime\n",
    "    combined_df['bloom_date'] = pd.to_datetime(combined_df['bloom_date'])\n",
    "\n",
    "    # Recreate year column\n",
    "    combined_df.insert(1, 'year', combined_df['bloom_date'].dt.year)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c63b3772-ede6-45b5-a097-717b902e0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(validation_path, cleaned_path):\n",
    "    # Check if the path exists\n",
    "    if not os.path.exists(validation_path):\n",
    "        print(f\"Path '{validation_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(cleaned_path):\n",
    "        print(f\"Path '{cleaned_path}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    df_dict = {}\n",
    "    \n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(validation_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            # Construct the full file path\n",
    "            v_file_path = os.path.join(validation_path, filename)\n",
    "            c_file_path = os.path.join(cleaned_path, filename)\n",
    "            \n",
    "            # Read the CSV file into a pandas DataFrame\n",
    "            df = clean_df(v_file_path, c_file_path)\n",
    "\n",
    "            # Append the cleaned df to the list\n",
    "            df_dict[filename] = df\n",
    "    \n",
    "    # Return the list of cleaned dfs\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "610ec210-ecbb-46eb-bcba-792e22d87b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame()\n",
    "\n",
    "for index in range(0, len(VALIDATION_PATHS)):\n",
    "    # Process the raw data\n",
    "    df_dict = combine_files(VALIDATION_PATHS[index], CLEANED_PATHS[index])\n",
    "    \n",
    "    # Output the aggregated files\n",
    "    for file_name in df_dict:\n",
    "        df_dict[file_name].to_csv(f\"{INDIV_OUT_PATH}{file_name}\", index=False)\n",
    "        \n",
    "        combined_df = pd.concat([combined_df, df_dict[file_name]], ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3194a1-76e4-446b-a709-fc48d64315f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle missing values, use the mean of each feature\n",
    "combined_df = combined_df.fillna(combined_df.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "962640a2-404e-445a-ab7f-ef06008115d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(f\"{COMBINED_OUT_PATH}combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced20ee-fd58-498f-877a-a9f3b1eb6f93",
   "metadata": {},
   "source": [
    "### Create a map to show locations represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "520c1400-bb75-4342-a3cd-31ea76efb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "mymap = folium.Map(zoom_start=5, tiles='OpenStreetMap')\n",
    "\n",
    "# Add markers for each location in the dataset\n",
    "for index, row in combined_df.iterrows():\n",
    "    folium.Marker(location=[row['lat'], row['long']]).add_to(mymap)\n",
    "\n",
    "# Save the map to an HTML file\n",
    "mymap.save('../figures/included_locations.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
